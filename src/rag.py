def retrieve_documents(query: str):
    """
    Retrieves relevant documents from the FAISS vector store based on the input query.
    
    Args:
        query (str): The query string to search for in the vector store.
    
    Returns:
        list: A list of retrieved documents.
    """
    # Retrieve documents from the vector store
    retrieved_docs = retriever.invoke(query)
    return retrieved_docs


def augment_context(retrieved_docs):
    """
    Augments the context for the LLM by formatting the retrieved documents.
    
    Args:
        retrieved_docs (list): A list of retrieved documents.
    
    Returns:
        str: A formatted context string.
    """
    # Format the retrieved documents into a context string
    context = "\n\n".join([doc.page_content for doc in retrieved_docs])
    return context


def generate_answer(context: str, query: str):
    """
    Generates an answer using the OpenRouter model based on the provided context and query.
    
    Args:
        context (str): The context string to provide to the model.
        query (str): The original query string.
    
    Returns:
        str: The generated answer from the model.
    """
    # Create a detailed prompt for the LLM
    prompt_template = f"""
    You are an expert assistant. Use the following context to answer the question accurately.
    If the answer is not found in the context, state that you don't know.

    CONTEXT:
    {context}

    QUESTION:
    {query}

    ANSWER:
    """

    # Send the prompt to the OpenRouter model
    completion = client.chat.completions.create(
        model="mistralai/mistral-7b-instruct:free",
        messages=[
            {
                "role": "user",
                "content": prompt_template,
            }
        ]
    )
    
    return completion.choices[0].message.content


def answer_query(query: str):
    """
    Performs the RAG process: Retrieve, Augment, and Generate.
    
    Args:
        query (str): The query string to answer.
    
    Returns:
        str: The final answer generated by the model.
    """
    # Retrieve relevant documents
    retrieved_docs = retrieve_documents(query)
    
    # Augment the context
    context = augment_context(retrieved_docs)
    
    # Generate the answer
    answer = generate_answer(context, query)
    
    return answer